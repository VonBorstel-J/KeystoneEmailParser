# .env

# OpenAI API Key
OPENAI_API_KEY=your_openai_api_key

# Local LLM API Endpoint
LOCAL_LLM_API_ENDPOINT=http://localhost:3000/v1/completions

# Ai Tings
HF_TOKEN=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
HF_HOME=D:\AiHub
TRANSFORMERS_CACHE=D:\AiHub

# Model configuration
MODEL_TIMEOUT=500
BATCH_SIZE=1
MODEL_RETRIES=3

# CUDA settings
CUDA_VISIBLE_DEVICES=0  # Use first GPU
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:6144
torch.cuda.set_per_process_memory_fraction(0.9)
torch.backends.cuda.cufft_plan_cache.clear()

