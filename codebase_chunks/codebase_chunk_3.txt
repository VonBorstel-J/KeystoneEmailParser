
            filename: 'fonts/[name][ext][query]',
          },
        },
      ],
    },
    resolve: {
      extensions: ['.js', '.jsx', '.css'],
      alias: {
        '@': path.resolve(__dirname, 'frontend'),
        '@components': path.resolve(__dirname, 'frontend/components'),
        '@actions': path.resolve(__dirname, 'frontend/actions'),
        '@reducers': path.resolve(__dirname, 'frontend/reducers'),
        '@core': path.resolve(__dirname, 'frontend/core'),
        '@utils': path.resolve(__dirname, 'frontend/utils'),
        '@css': path.resolve(__dirname, 'frontend/static/css'),
      },
    },
    plugins: [
      new MiniCssExtractPlugin({
        filename: isProduction ? '[name].[contenthash].css' : '[name].css',
      }),
      new HtmlWebpackPlugin({
        template: path.resolve(__dirname, 'templates', 'index.html'),
        filename: 'index.html',
        inject: 'body',
        minify: isProduction
          ? {
              removeComments: true,
              collapseWhitespace: true,
              removeRedundantAttributes: true,
              useShortDoctype: true,
            }
          : false,
      }),
      new CleanWebpackPlugin(), // Ensures clean build folders
      new webpack.DefinePlugin({
        'process.env.NODE_ENV': JSON.stringify(isProduction ? 'production' : 'development'),
      }),
    ],
    optimization: {
      splitChunks: {
        chunks: 'all',
        cacheGroups: {
          vendor: {
            test: /[\\/]node_modules[\\/]/,
            name: 'vendors',
            chunks: 'all',
          },
        },
      },
      runtimeChunk: 'single',
    },
    performance: {
      hints: isProduction ? 'warning' : false,
    },
  };
};




# -------------------- C:\Users\jorda\OneDrive\Desktop\Quickbase Dev Work\KeystoneEmailParser\tailwind.config.js --------------------

// tailwind.config.js
module.exports = {
  content: ['./frontend/**/*.{js,jsx,ts,tsx}', './templates/**/*.html'],
  darkMode: 'media', // Supports system preference for dark mode
  theme: {
    extend: {
      colors: {
        primary: {
          light: '#63b3ed',
          DEFAULT: '#3182ce',
          dark: '#2c5282',
        },
        secondary: {
          light: '#fbd38d',
          DEFAULT: '#ed8936',
          dark: '#c05621',
        },
      },
      spacing: {
        18: '4.5rem', // Custom spacing value for more flexibility
      },
      borderRadius: {
        'xl': '1.25rem', // Extends border radius options for rounded corners
      },
      boxShadow: {
        'custom-light': '0 4px 6px rgba(0, 0, 0, 0.1)',
        'custom-dark': '0 8px 12px rgba(0, 0, 0, 0.3)',
      },
    },
  },
  plugins: [
    require('@tailwindcss/forms'), // Adds better form styles out of the box
    require('@tailwindcss/typography'), // Adds utilities for improving typography
  ],
};




# -------------------- C:\Users\jorda\OneDrive\Desktop\Quickbase Dev Work\KeystoneEmailParser\package.json --------------------

{
  "name": "keystone-email-parser",
  "version": "1.0.0",
  "description": "Email parsing application with React frontend",
  "main": "static/js/main.js",
  "scripts": {
    "start": "concurrently \"npm run start:backend\" \"npm run start:frontend\"",
    "start:frontend": "webpack serve --mode development",
    "start:backend": "cross-env FLASK_ENV=development python app.py",
    "build": "webpack --mode development",
    "build:prod": "webpack --mode production",
    "watch": "webpack --watch --mode development",
    "clean": "rimraf static/dist",
    "lint": "eslint frontend/**/*.{js,jsx}",
    "test": "echo \"No tests specified\" && exit 0"
  },
  "dependencies": {
    "@babel/runtime": "^7.22.5",
    "@headlessui/react": "^2.2.0",
    "@reduxjs/toolkit": "^1.9.5",
    "axios": "^1.7.7",
    "dompurify": "^3.1.7",
    "file-saver": "^2.0.5",
    "jspdf": "^2.5.1",
    "lodash": "^4.17.21",
    "lottie-web": "^5.12.2",
    "lucide-react": "^0.263.1",
    "prop-types": "^15.8.1",
    "react": "^18.2.0",
    "react-copy-to-clipboard": "^5.1.0",
    "react-dom": "^18.2.0",
    "react-focus-lock": "^2.13.2",
    "react-redux": "^8.1.1",
    "react-syntax-highlighter": "^15.6.1",
    "recharts": "^2.5.0",
    "redux": "^4.2.1",
    "redux-thunk": "^2.4.2",
    "socket.io-client": "^4.5.4",
    "uuid": "^11.0.2"
  },
  "devDependencies": {
    "@babel/core": "^7.26.0",
    "@babel/plugin-proposal-class-properties": "^7.18.6",
    "@babel/plugin-proposal-optional-chaining": "^7.21.0",
    "@babel/plugin-transform-nullish-coalescing-operator": "^7.25.9",
    "@babel/plugin-transform-runtime": "^7.25.9",
    "@babel/preset-env": "^7.26.0",
    "@babel/preset-react": "^7.25.9",
    "autoprefixer": "^10.4.20",
    "babel-loader": "^9.2.1",
    "clean-webpack-plugin": "^4.0.0",
    "concurrently": "^9.0.1",
    "cross-env": "^7.0.3",
    "css-loader": "^6.11.0",
    "del-cli": "^6.0.0",
    "eslint": "^8.56.0",
    "eslint-plugin-react": "^7.33.2",
    "eslint-plugin-react-hooks": "^4.6.0",
    "html-webpack-plugin": "^5.6.3",
    "mini-css-extract-plugin": "^2.9.1",
    "postcss": "^8.4.47",
    "postcss-loader": "^7.3.4",
    "rimraf": "^5.0.5",
    "style-loader": "^3.3.4",
    "tailwindcss": "^3.4.14",
    "webpack": "^5.95.0",
    "webpack-cli": "^5.1.4",
    "webpack-dev-server": "^4.15.0"
  },
  "browser": {
    "@": "./frontend",
    "@components": "./frontend/components",
    "@actions": "./frontend/actions",
    "@reducers": "./frontend/reducers",
    "@core": "./frontend/core",
    "@utils": "./frontend/utils",
    "@css": "./frontend/static/css"
  },
  "engines": {
    "node": ">=14.0.0",
    "npm": ">=6.0.0"
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 2 Chrome versions",
      "last 2 Firefox versions",
      "last 2 Safari versions"
    ]
  }
}




# -------------------- C:\Users\jorda\OneDrive\Desktop\Quickbase Dev Work\KeystoneEmailParser\jsconfig.json --------------------

{
  "compilerOptions": {
    "target": "ES6",
    "baseUrl": ".",
    "paths": {
      "@/*": ["frontend/*"],
      "@components/*": ["frontend/components/*"],
      "@actions/*": ["frontend/actions/*"],
      "@reducers/*": ["frontend/reducers/*"],
      "@core/*": ["frontend/core/*"],
      "@utils/*": ["frontend/utils/*"],
      "@css/*": ["frontend/static/css/*"]
    },
    "allowSyntheticDefaultImports": true,
    "jsx": "react"
  },
  "include": ["frontend/**/*"],
  "exclude": ["node_modules", "static/dist", "**/*.test.js"]
}




# -------------------- C:\Users\jorda\OneDrive\Desktop\Quickbase Dev Work\KeystoneEmailParser\app.py --------------------

# src/app.py
eventlet.monkey_patch()
# Set memory fraction to 90% of total GPU memory
if torch.cuda.is_available():
    torch.cuda.set_per_process_memory_fraction(0.9)
    # Clear the FFT plan cache for potentially faster CUDA operations
    torch.backends.cuda.cufft_plan_cache.clear()
def setup_logging() -> logging.Logger:
    formatter = json_log_formatter.JSONFormatter()
    json_handler = logging.StreamHandler()
    json_handler.setFormatter(formatter)
    logger = logging.getLogger("AppLogger")
    logger.addHandler(json_handler)
    logger.setLevel(logging.DEBUG)
    return logger
def init_app() -> (Flask, SocketIO):
    load_dotenv()
    app = Flask(__name__, static_folder='static', template_folder='templates')
    CORS(app)  # Enable CORS
    socketio = SocketIO(
        app,
        cors_allowed_origins="*",
        logger=True,
        engineio_logger=True,
        async_mode="eventlet",
    )
    return app, socketio
def setup_cache_dirs(logger: logging.Logger):
    cache_dir = str(Path("D:/AiHub"))
    os.environ["HF_HOME"] = cache_dir
    os.makedirs(cache_dir, exist_ok=True)
    logger.info("Cache directory set to: %s", cache_dir)
    if torch.cuda.is_available():
        logger.info("CUDA available: %s", torch.cuda.get_device_name(0))
    else:
        logger.info("CUDA not available, using CPU")
logger = setup_logging()
app, socketio = init_app()
def format_schema_output(formatted_data: Dict[str, Any]) -> str:
    output = []
    for section, fields in formatted_data.items():
        output.append(section)
        output.append("")
        for field, value in fields.items():
            output.append(f"{field}: {value}")
        output.append("")
    return "\n".join(output)
def make_serializable(obj: Any) -> Any:
    if isinstance(obj, (np.float32, np.float64)):
        return float(obj)
    elif isinstance(obj, (np.int32, np.int64)):
        return int(obj)
    elif isinstance(obj, dict):
        return {k: make_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [make_serializable(element) for element in obj]
    elif isinstance(obj, tuple):
        return tuple(make_serializable(element) for element in obj)
    elif isinstance(obj, set):
        return [make_serializable(element) for element in obj]
    elif isinstance(obj, (float, int, str)):
        return obj
    else:
        return str(obj)
def background_parse(
    sid: str,
    parser_option: str,
    email_content: str,
    document_image: Optional[Image.Image],
):
    # Create event loop for this thread
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        input_type = None
        if email_content and document_image:
            input_type = 'both'
        elif email_content:
            input_type = 'text'
        elif document_image:
            input_type = 'image'
        parser = ParserRegistry.get_parser(
            parser_option=ParserOption(parser_option),
            socketio=socketio,
            sid=sid,
        )
        if parser is None:
            socketio.emit(
                "parsing_error", {"error": f"Parser for option {parser_option} not found."}, room=sid
            )
            return
        with parser:
            if not parser.is_initialized:
                parser.initialize(input_type=input_type)
            if not parser.health_check():
                socketio.emit(
                    "parsing_error", {"error": "Parser health check failed."}, room=sid
                )
                return
            socketio.emit(
                "parsing_started", {"message": "Parsing started..."}, room=sid
            )
            stages = [
                {"stage": "Initializing parser", "progress": 10},
                {"stage": "Processing email content", "progress": 30},
                {"stage": "Extracting entities", "progress": 50},
                {"stage": "Finalizing results", "progress": 80},
                {"stage": "Completed", "progress": 100},
            ]
            for step in stages:
                socketio.emit(
                    "parsing_progress",
                    {"stage": step["stage"], "progress": step["progress"]},
                    room=sid,
                )
                socketio.sleep(1)
            result = parser.parse_email(
                email_content=email_content, document_image=document_image
            )
            # Handle structured_data and metadata
            structured_data = result.get("structured_data", {})
            metadata = result.get("metadata", {})
            # Optionally, log or use metadata
            logger.debug("Metadata from parsing: %s", metadata)
            if "email_metadata" in structured_data:
                formatted_text = format_schema_output(structured_data["email_metadata"])
                structured_data["formatted_schema"] = formatted_text
            serializable_result = make_serializable(structured_data)
            logger.debug("Serialized Result: %s", serializable_result)
            socketio.emit(
                "parsing_completed", {"result": serializable_result}, room=sid
            )
    except Exception as e:
        logger.error("Error during parsing: %s", e, exc_info=True)
        error_info = {
            "type": "unexpected_error",
            "message": f"An unexpected error occurred: {str(e)}",
            "time": datetime.now(timezone.utc).isoformat(),
            "exc_info": traceback.format_exc(),
        }
        serializable_error = make_serializable(error_info)
        socketio.emit("parsing_error", {"error": serializable_error}, room=sid)
    finally:
        loop.close()
# Frontend route
@app.route("/", methods=["GET"])
def index():
    logger.info("Rendering index page.")
    return render_template("index.html")
# Favicon route
@app.route("/favicon.ico")
def favicon_route():
    favicon_path = os.path.join(app.root_path, "static", "favicon.ico")
    if os.path.exists(favicon_path):
        return send_from_directory(
            os.path.join(app.root_path, "static"),
            "favicon.ico",
            mimetype="image/vnd.microsoft.icon",
        )
    logger.warning("favicon.ico not found at path: %s", favicon_path)
    return jsonify({"error_message": "favicon.ico not found."}), 404
# API routes - all prefixed with /api
@app.route("/api/parse_email", methods=["POST"])
def parse_email_route():
    email_content = request.form.get("email_content", "").strip()
    image_file = request.files.get("document_image")
    parser_option_str = request.form.get("parser_option", "").strip()
    socket_id = request.form.get("socket_id")
    if not email_content and not image_file:
        logger.warning("No email content or document image provided.")
        return (
            jsonify(
                {"error_message": "Please provide email content or document image"}
            ),
            400,
        )
    if not parser_option_str:
        logger.warning("No parser option selected.")
        return jsonify({"error_message": "Please select a parser option."}), 400
    sid = socket_id
    if not sid:
        logger.warning("No socket ID provided.")
        return jsonify({"error_message": "Socket ID not provided."}), 400
    logger.info("Received Socket ID: %s", sid)
    try:
        parser_option = ParserOption(parser_option_str)
    except ValueError:
        logger.warning("Invalid parser option selected: %s", parser_option_str)
        return (
            jsonify({"error_message": f"Invalid parser option: {parser_option_str}"}),
            400,
        )
    try:
        # Adjusted get_parser call without 'input_type'
        parser_config = ParserRegistry.get_parser(parser_option, socketio=socketio, sid=sid)
    except InitializationError as ie:
        logger.error("Parser initialization failed: %s", ie)
        return jsonify({"error_message": str(ie)}), 500
    except Exception as e:
        logger.error(
            "Unexpected error during parser initialization: %s", e, exc_info=True
        )
        return jsonify({"error_message": "Parser initialization failed"}), 500
    if parser_config is None:
        logger.error("Parser could not be initialized.")
        return jsonify({"error_message": "Parser could not be initialized"}), 500
    document_image = None
    if image_file:
        try:
            document_image = Image.open(io.BytesIO(image_file.read()))
        except Exception as e:
            logger.error("Image processing failed: %s", e, exc_info=True)
            return jsonify({"error_message": "Invalid image format"}), 400
    socketio.start_background_task(
        background_parse, sid, parser_option_str, email_content, document_image
    )
    logger.info("Parsing started for Socket ID: %s", sid)
    return jsonify({"message": "Parsing started"}), 202
@app.route("/api/health", methods=["GET"])
def health_check_route():
    try:
        status = ParserRegistry.health_check()
        logger.info("Health check passed.")
        return jsonify({"status": "healthy", "parsers": status}), 200
    except Exception as e:
        logger.error("Health check failed: %s", e, exc_info=True)
        return jsonify({"status": "unhealthy", "error": str(e)}), 500
# Error handlers
@app.errorhandler(404)
def not_found_error(error):
    logger.warning("404 error: %s not found. Exception: %s", request.url, error)
    return jsonify({"error": "Endpoint not found"}), 404
@app.errorhandler(500)
def internal_error(error):
    logger.error("Internal server error: %s", error, exc_info=True)
    return jsonify({"error": "Internal server error"}), 500
@app.errorhandler(Exception)
def handle_exception(e: Exception):
    logger.error("Unhandled exception: %s", e, exc_info=True)
    return jsonify({"error_message": "An internal error occurred."}), 500
@app.errorhandler(404)
def page_not_found(e: Exception):
    logger.warning("404 error: %s not found. Exception: %s", request.url, e)
    return (
        jsonify({"error_message": "The requested URL was not found on the server."}),
        404,
    )
# SocketIO event handlers
@socketio.on("connect")
def handle_connect():
    sid = request.sid
    logger.info("Client connected: %s", sid)
    logger.debug("Connection headers: %s", request.headers)
    logger.debug("Connection environment: %s", request.environ)
    # Emit a test message to verify connection
    try:
        socketio.emit("connection_test", {"status": "connected", "sid": sid}, room=sid)
        logger.debug("Sent connection test to client %s", sid)
    except Exception as e:
        logger.error("Failed to emit connection test: %s", e, exc_info=True)
@socketio.on("disconnect")
def handle_disconnect():
    sid = request.sid
    logger.info("Client disconnected: %s", sid)
    logger.debug("Disconnect reason: %s", request.environ.get('disconnection_reason', 'unknown'))
@socketio.on_error()
def error_handler(e):
    logger.error("SocketIO error: %s", e, exc_info=True)
    if request.sid:
        socketio.emit(
            "parsing_error",
            {"error": "An unexpected error occurred during socket communication"},
            room=request.sid
        )
def signal_handler(_sig, _frame):
    try:
        logger.info("Shutdown initiated...")
        ParserRegistry.cleanup_parsers()
        logger.info("Cleanup completed successfully.")
    except Exception as e:
        logger.error("Error during cleanup: %s", e, exc_info=True)
    finally:
        sys.exit(0)
if __name__ == "__main__":
    try:
        logger.info("Starting application initialization...")
        setup_cache_dirs(logger)
        logger.info("Loading configuration...")
        Config.initialize()
        logger.info("Configuration loaded successfully")
        host = os.getenv("HOST", "127.0.0.1")
        port = int(os.getenv("PORT", "5000"))
        logger.info("Server will start on %s:%d", host, port)
        static_dir = os.path.join(app.root_path, "static")
        if not os.path.exists(static_dir):
            os.makedirs(static_dir)
            logger.info("Created static directory at %s", static_dir)
        ParserRegistry.initialize_parsers()
        logger.info("Parsers initialized successfully")
        # Register signal handlers for graceful shutdown
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        socketio.run(app, host=host, port=port, debug=True, use_reloader=False)
    except InitializationError as ie:
        logger.critical(
            "Parser initialization failed during startup: %s", ie, exc_info=True
        )
        try:
            ParserRegistry.cleanup_parsers()
        except Exception as cleanup_e:
            logger.error(
                "Error during cleanup after failed startup: %s",
                cleanup_e,
                exc_info=True,
            )
        sys.exit(1)
    except Exception as e:
        logger.critical("Failed to start the Flask application: %s", e, exc_info=True)
        try:
            ParserRegistry.cleanup_parsers()
        except Exception as cleanup_e:
            logger.error(
                "Error during cleanup after failed startup: %s",
                cleanup_e,
                exc_info=True,
            )
        sys.exit(1)




# -------------------- C:\Users\jorda\OneDrive\Desktop\Quickbase Dev Work\KeystoneEmailParser\.babelrc --------------------

{
  "presets": [
    [
      "@babel/preset-env",
      {
        "targets": {
          "browsers": [">0.25%", "not ie 11", "not op_mini all"]
        },
        "useBuiltIns": "usage",
        "corejs": "3.21"
      }
    ],
    "@babel/preset-react"
  ],
  "plugins": [
    "@babel/plugin-proposal-class-properties",
    "@babel/plugin-transform-nullish-coalescing-operator", // Updated here
    "@babel/plugin-proposal-optional-chaining",
    [
      "@babel/plugin-transform-runtime",
      {
        "corejs": 3,
        "regenerator": true,
        "helpers": true
      }
    ]
  ]
}




# -------------------- C:\Users\jorda\OneDrive\Desktop\Quickbase Dev Work\KeystoneEmailParser\postcss.config.js --------------------

// postcss.config.js
module.exports = {
    plugins: {
      'tailwindcss': {},
      'autoprefixer': {},
    }
  };



# -------------------- C:\Users\jorda\OneDrive\Desktop\Quickbase Dev Work\KeystoneEmailParser\importSchema.json --------------------

{
  "RequestingParty": {
    "InsuranceCompany": "",
    "Handler": "",
    "CarrierClaimNumber": ""
  },
  "InsuredInformation": {
    "Name": "",
    "ContactNumber": "",
    "LossAddress": "",
    "PublicAdjuster": "",
    "OwnershipStatus": ""
  },
  "AdjusterInformation": {
    "AdjusterName": "",
    "AdjusterPhoneNumber": "",
    "AdjusterEmail": "",
    "JobTitle": "",
    "Address": "",
    "PolicyNumber": ""
  },
  "AssignmentInformation": {
    "DateOfLoss": "",
    "CauseOfLoss": "",
    "FactsOfLoss": "",
    "LossDescription": "",
    "ResidenceOccupiedDuringLoss": "",
    "WasSomeoneHomeAtTimeOfDamage": "",
    "RepairOrMitigationProgress": "",
    "Type": "",
    "InspectionType": ""
  },
  "AssignmentType": {
    "Wind": false,
    "Structural": false,
    "Hail": false,
    "Foundation": false,
    "Other": {
      "isChecked": false,
      "details": ""
    }
  },
  "AdditionalDetails": "",
  "Attachments": []
}




# -------------------- C:\Users\jorda\OneDrive\Desktop\Quickbase Dev Work\KeystoneEmailParser\.env --------------------

# .env
# OpenAI API Key
OPENAI_API_KEY=your_openai_api_key
# Local LLM API Endpoint
LOCAL_LLM_API_ENDPOINT=http://localhost:3000/v1/completions
# Ai Tings
HF_TOKEN=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
HF_HOME=D:\AiHub
TRANSFORMERS_CACHE=D:\AiHub
# Model configuration
MODEL_TIMEOUT=500
BATCH_SIZE=1
MODEL_RETRIES=3
# CUDA settings
CUDA_VISIBLE_DEVICES=0  # Use first GPU
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:6144
torch.cuda.set_per_process_memory_fraction(0.9)
torch.backends.cuda.cufft_plan_cache.clear()


